{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data: drop, replace, melt y otras cositas\n",
    "\n",
    "En esta ayudantía haremos un repaso en metodos de limpieza de datos, para esto repasaremoslas funciones más comunes y luego iremos a la actividad con dos ejemplos prácticos de limpieza de datos\n",
    "\n",
    "## Melt\n",
    "\n",
    "Melt es una funcion que nos permite, de cierta forma, convertir calumnas en filas, veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'}, \n",
    "                   'B': {0: 1, 1: 3, 2: 5},\n",
    "                   'C': {0: 2, 1: 4, 2: 6}}) #creamos un dataframe cualquiera\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(df, id_vars=['A'], value_vars=['B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos ver que, transformamos la columna `B` en una fila de variables, en este caso no es muy útil, al fin y al cabo todo lo que hicimos fue presentar la misma información gastando más especio, pero veamos el ejemplo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tiene más sentido, convertimos ambas columnas en datos. En resumen, `pd.melt` nos permite transformar `dataframes` \"anchos\" en `dataframes` \"largos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividades\n",
    "Para estas actividades los que haremos será limpiar dos bases de datos, una será limpiar dos bases de datos con el fin de dejarlas listas para uso\n",
    "\n",
    "# 1.- Libros de la Bilioteca Británica\n",
    "\n",
    "En esta primera actividad limpiaremos una base de datos de libros de la bilbioteca británica, cortesia de [realpython](https://github.com/realpython/python-data-cleaning), como siempre, lo primero que haremos será invocar al dataframe, y ver como está ordenado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/BL-Flickr-Images-Book.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que no es uno muy largo, pero de todas formas vamos a asumir que sabemos que las columnas `'Edition Statement','Corporate Author','Corporate Contributors','Former owner','Engraver','Contributors','Issuance type','Shelfmarks'` no las vamos a necesitar, por lo que procederemos a dropearlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "           #fill \n",
    "          ]\n",
    "\n",
    "df.drop(#fill\n",
    "        , inplace = #fill\n",
    "        , axis = #fill\n",
    "       )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos un *dataframe* de un tamaño mucho más manejable, además tenemos una columna llamada `Identifier`, esta puede que nos sea útil como indice, pero antes, utiliza el metodo `.is_unique` para revisar que el valor para cada fila sea único. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Identifier'].#fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pandas, no es necesario el valor del indice sea único, pero algunos métodos lo exigen, así que es bueno tenerlo en cuenta. Ahora, hagamos que la columna `Identifier` sea el indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(#fill\n",
    "             , inplace = #fill\n",
    "            )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos el dataset un poco más limpio, procederemos a revisar en que sitiacion nos encontramos con `NaNs`, para eso utiliza el metodo `.info()` para reviar cuantos valores no nulos hay por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.#fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos una cantidad no menos de valores nulos en `Publisher` y en `Author`, asumiremos que no importa que haya valroes nulos en la primera, pero que si no contienen el autor no nos sirven para el analizis que nos interesa, para esto vamos a dropear todas las filas que tengan un valor nulo en la columna `Author`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(#fill\n",
    "          , inplace = #fill\n",
    "         )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- GDP per Captita en América del Sur\n",
    "\n",
    "Para esta parte usaremos los datos de creciemiento de GDP per cápita porcentuales de paises en Sudamerica obtenidos en [World Bank Open Data](https://data.worldbank.org/), el proceso de obntenerlos el algo complejo, pero al final nos deja con un csv que contiene estos datos para los 10 paises con mayor GDP en sudamerica. Ahora, lo de siempre, invocar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/gdp_pc_growth_per_sa.csv\")\n",
    "df #no usamos .head() porque el largo de la serie es manejable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar un par de problemas a primera vista, tenemos un par de columnas que no vamos a usar, muchos valores nulos, nombres raros en las columnas. Veamos primero que podemos hacer en las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De buenas a primeras, las columnas `'Series Name', 'Series Code','Country Code', '2020 [YR2020]'` no las usaremos, las primeras tres porque son codigos, y la uiltima porque aun no tiene datos, asi que las podemos dropear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "            #fill\n",
    "          ]\n",
    "df.drop(#fill\n",
    "        , inplace = #fill)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, las filas de la 10 a la 14 no tienen valores, por lo que tambien las vamos a dropear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(#fill\n",
    "        , inplace=True\n",
    "       )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemmos un dataframe que va tomando forma, pero esos nombres de columnas las complicados de lo necesario, para esto, usa el metodo que estimes conveniente para quedarte solo con los 4 primeros caracteres de cada una, y usar esos como nombre de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = #fill\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a revisar ahora los tipos de datos, para ver que todo esté en orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué los años de 2015 a 2019 aparecen como `object`? Quizás una inspeccion rápida del *dataframe* nos de una respuesta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que, en Venezuela no tenenemos valores para 2015 en adelante, y estos estan rellenos con `'..'`, para esto usaremos un `replace` y los cambiarmos por `np.nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(#fill\n",
    "           , np.nan #fill\n",
    "           , inplace = #fill\n",
    "          )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero la pega aun no está hecha, hay que cambiar el *dtype* de las columnas que arreglamos, para eso ocupa `.as_type()` en las columnas que nos interesan, o usa el método que más te acomode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[-5:]] = #fill\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos todo más o menos ordenado, utilizaremos `pd.melt()` para transformar nuestro dataframe en uno con las columnas `'anno'` y `'gdp_pc'`, donde las *id's* sean los paises y los valores los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df = pd.melt(df, id_vars = 'country', value_vars = df.columns[1:], var_name='anno', value_name='gdp_pc')\n",
    "melt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df.groupby('anno').apply(lambda x: x.mean().drop('anno'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df.groupby('country').apply(lambda x: x.mean().drop('country'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
