{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es el One Hot Encoding? ¿Por qué y cuando debemos usarlo?\n",
    "\n",
    "One hot encoding es un proceso en el cual variables categoiricas son convertidas en una forma en la que se la podemos entregar a un algoritmo de *Machine Learning* para hacer un mejor trabajo al momento de predecir\n",
    "is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
    "\n",
    "Veamos, estas jugnado con un modelo de ML y te encientras con esto del *“One hot encoding”* en todos lados, haces lo que siempre haces en estos casos y revisas la [documenacion](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?ref=hackernoon.com) de sklearn para *one hot encoder* y dice: “Encode categorical integer features using a one-hot aka one-of-K scheme.” ,i.e, no dice nada, esto es lo malo de las docuimentaciones, pueden ser un poco \"circulares\" a ratos, así que veamos un ejemplo de que es lo que es esto:\n",
    "\n",
    "### Supongamos el siguiente dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>categorical_value</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VW</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>1</td>\n",
       "      <td>10011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name  categorical_value  price\n",
       "0           VW                  1  20000\n",
       "1        Acura                  1  10011\n",
       "2        Honda                  2  50000\n",
       "3        Honda                  3  10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'company_name':['VW', 'Acura', 'Honda', 'Honda'], 'categorical_value':[1,1,2,3], 'price':[20000, 10011, 50000, 10000]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `categorical_value` representa el valor numerico de la entrada en el dataset, i.e., si hubiera una cuarta compañia, esta tendría un valor de 4. De forma que el numero de valores únicos aumenta, los valroes categoricos también lo hacen. \n",
    "\n",
    "Podemos usar [*labelEncoder*](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?ref=hackernoon.com) de sklearn para generar esta columna en base a una columna de valores categoricos (aunque este iría de 0 a n-1)\n",
    "\n",
    "Ahora, centrandonos en lo que nos interesa, si seguimos las intruscciones que nos dan en la documentacion que citamos al principio, obtendríamos el siguiente dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>categorical_value</th>\n",
       "      <th>price</th>\n",
       "      <th>is_Acura</th>\n",
       "      <th>is_Honda</th>\n",
       "      <th>is_VW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VW</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>1</td>\n",
       "      <td>10011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name  categorical_value  price  is_Acura  is_Honda  is_VW\n",
       "0           VW                  1  20000       0.0       0.0    1.0\n",
       "1        Acura                  1  10011       1.0       0.0    0.0\n",
       "2        Honda                  2  50000       0.0       1.0    0.0\n",
       "3        Honda                  3  10000       0.0       1.0    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df[['company_name']]).toarray())\n",
    "oh_df = df.join(enc_df)\n",
    "oh_df.columns = list(oh_df.columns[:3])+['is_Acura', 'is_Honda', 'is_VW'] #esto no es necesario, es solo con el fin de ilustrar el ejemplo\n",
    "oh_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 indica que no existe mientras que 1 indica que si lo hace.\n",
    "\n",
    "Antes de seguir, ¿se les ocurre porque usar la columnas *categorical_value* no es suficiente?\n",
    "\n",
    "El problema con esto es que implica un orden, asume que una categoria con un mayor valor numerico es una \"mejor categoría\"\n",
    "\n",
    "A qué me refiero con esto, esta forma de organizacion asume qué VW > Acura > Honda based basado en los valores categoricos, asumamos que el modelo en algun momento desea tomar un promedio, entonces nos daría 1+3 = 4/2 =2. Esto implica que el promedio de VW y Honda es Acura. Creo que todos podemos estar de acuerdo que hay algo mal con eso. Este modelo terminaría por perder capacidad dado este error.\n",
    "\n",
    "Este es el motivo por el cual usamos *one hot encoder* para “binarizar” los datos de las categorias para incluirlas en nuestro modelo\n",
    "\n",
    "Ahora, veamos un ejemplo un poco más robusto. Usando una base de datos de cancer de mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'1'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'central'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'30-34'</td>\n",
       "      <td>'3-5'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'right_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1        2      3      4    5        6           7      8  \\\n",
       "0  '40-49'  'premeno'  '15-19'  '0-2'  'yes'  '3'  'right'   'left_up'   'no'   \n",
       "1  '50-59'     'ge40'  '15-19'  '0-2'   'no'  '1'  'right'   'central'   'no'   \n",
       "2  '50-59'     'ge40'  '35-39'  '0-2'   'no'  '2'   'left'  'left_low'   'no'   \n",
       "3  '40-49'  'premeno'  '35-39'  '0-2'  'yes'  '3'  'right'  'left_low'  'yes'   \n",
       "4  '40-49'  'premeno'  '30-34'  '3-5'  'yes'  '2'   'left'  'right_up'   'no'   \n",
       "\n",
       "                        9  \n",
       "0     'recurrence-events'  \n",
       "1  'no-recurrence-events'  \n",
       "2     'recurrence-events'  \n",
       "3  'no-recurrence-events'  \n",
       "4     'recurrence-events'  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\"\n",
    "dataset = pd.read_csv(url, header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a rescatar los datos como array para que sean un poco más fáciles de trabajar. También usaremos `LabelEncoder`, acá pueden ver su [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), pero el tl;dr, hace lo mismo pero crea una sola columna para \"esto pasa o no pasa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (286, 43)\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]] \n",
      "\n",
      " [1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "data = dataset.values\n",
    "# Los separamos entre input y output\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "# creamos el one hot encoder \n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X = onehot_encoder.fit_transform(X)\n",
    "# label con\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "# summarize the transformed data\n",
    "print('Input', X.shape)\n",
    "print(X[:5, :], '\\n\\n',y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a hacer una regresión logística rápida para nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# separamos los datos en train y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# one-hot encode \n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "# ordinal encode variable objetivo\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "# definimos el modelo\n",
    "model = LogisticRegression()\n",
    "# hacemos el fit\n",
    "model.fit(X_train, y_train)\n",
    "# predecimos\n",
    "yhat = model.predict(X_test)\n",
    "# evaluamos\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es el mejor modelo del mundo, pero hay muchos otros que podedríamos usar, pero lo que quiero vean es que pudimos transdormar un datates basicamente inutul en uno que podemos meter en un modelo, ahí les va a ustedes en su imaginación que es lo que pueden hacer. Dicho esto, ahora viene eso:\n",
    "\n",
    "### Actividades\n",
    "#### Actividad 1\n",
    "\n",
    "Para este ejercico usaremos los datos de kaggle de (House Prices: Advanced Regression Techniques)[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview]. Es una competencia, así que les recomiendo mirarla y participar si es que se animan! Les entregaré los datos amononados, de forma de centrarnos en lo que nos interesa en este momento. Filtraremos todos los datos que no son categoricos (el criterio será más de 10 valores únicos), y borraremos las columnas con datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# vamos a dropear donde no tengamos target\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "target = train_data.SalePrice\n",
    "\n",
    "# Como el objetivo no es manejar valores nan, y es un ejemplo\n",
    "# vamos a dropear las columnas con valores faltantes\n",
    "# si quieren aprender más sobre el tema recomiendo\n",
    "# https://www.kaggle.com/dansbecker/handling-missing-values\n",
    "cols_with_missing = [col for col in train_data.columns \n",
    "                                 if train_data[col].isnull().any()]                                  \n",
    "candidate_train_predictors = train_data.drop(['Id', 'SalePrice'] + cols_with_missing, axis=1)\n",
    "\n",
    "# \"cardinality\" es el numero de valores únicos\n",
    "# Lo usamos para seleccionar columnas categoricos\n",
    "# Esto es conveniente pero quizás algo arbitrario\n",
    "low_cardinality_cols = [cname for cname in candidate_train_predictors.columns if \n",
    "                                candidate_train_predictors[cname].nunique() < 10 and\n",
    "                                candidate_train_predictors[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in candidate_train_predictors.columns if \n",
    "                                candidate_train_predictors[cname].dtype in ['int64', 'float64']]\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "predictors = candidate_train_predictors[my_cols]\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los datos limpios, separen los datos (usen `random_state=42` y `test_size=0.33`) y utilizen el *encoder* para transformar los datos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = #fill\n",
    "y = #fill\n",
    "# separamos los datos en train y test \n",
    "X_train, X_test, y_train, y_test = #fill\n",
    "# one-hot encode \n",
    "onehot_encoder = #fill\n",
    "onehot_encoder.fit(#fill)\n",
    "X_train = onehot_encoder.transform(#fill)\n",
    "X_test = onehot_encoder.transform(#fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, usen un modelo a elección (ojalá no una regresión logística) para modelar las precios, y vean que tal les va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = #fill\n",
    "# hacemos el fit\n",
    "model.fit(#fill)\n",
    "# predecimos\n",
    "yhat = model.predict(#fill)\n",
    "# evaluamos\n",
    "accuracy = accuracy_score(#fill)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genial, ahora les toca un no tan grande desafío"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actividad 2: Ganenme\n",
    "\n",
    "Ahora que ya saben como funciona esto, les dejo el dataframe para que intenten ganarme. No debería ser muy dificil dado el modelo que ocupé, pero las unicas reglas es que deben usar los mismos parámetros para `train_test_split` y no repetir modelos que ya se hayan usado en este notebook. Suerte!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\"\n",
    "df = pd.read_csv(url, header=None)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
