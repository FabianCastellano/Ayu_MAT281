{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajando con datos desbalanceados\n",
    "\n",
    "Al trabajar en *data science* es normal encontrarse con bases de datos en las que un tipo de dato (en particular, uno que es de interes) aparece con mucha menos frecuencia que el resto de los datos, esto en común en particular cuando se intentan detectar anormalidades en un conjunto de datos. Estos tipo de datos a tener una distribución en la que la gran mayoría de los casos van a ser \"honestos\". En general hablamos de datos desbalanceados cuando al rededor de un 5% o menos de los datos son del tipo que estámos buscando. En estos casos modelos de *machine learning* suelen producir málos clasificadores al encontrarse con datos sitrubuidos de está manera, y para esto exiten métodos con los que trabajar.\n",
    "\n",
    "## Un ejemplo de datos desbalanceados\n",
    "\n",
    "Por lo tanto, para resumir, al intentar resolver desafíos comerciales específicos con conjuntos de datos desequilibrados, los clasificadores producidos por algoritmos estándar de aprendizaje automático pueden no dar resultados precisos. Además de las transacciones fraudulentas, otros ejemplos de un problema comercial común con un conjunto de datos desequilibrado son:\n",
    "\n",
    "* Conjuntos de datos para identificar la rotación de clientes donde una gran mayoría de clientes continuará utilizando el servicio. En concreto, empresas de telecomunicaciones en las que la tasa de rotación sea inferior al 2%.\n",
    "* Conjuntos de datos para identificar enfermedades raras en diagnósticos médicos, etc.\n",
    "* Desastres naturales como terremotos\n",
    "\n",
    "## Desafíos con las técnicas estándar de aprendizaje automático\n",
    "\n",
    "Los métodos de evaluación de modelos convencionales no miden con precisión el rendimiento del modelo cuando se enfrentan a conjuntos de datos desequilibrados.\n",
    "\n",
    "Los algoritmos de clasificador estándar como el árbol de decisiones y la regresión logística tienen un sesgo hacia las clases que tienen un número de instancias. Tienden a predecir solo los datos de la clase mayoritaria. Las características de la clase minoritaria se tratan como ruido y a menudo se ignoran. Por lo tanto, existe una alta probabilidad de clasificación errónea de la clase minoritaria en comparación con la clase mayoritaria.\n",
    "\n",
    "La evaluación del rendimiento de un algoritmo de clasificación se mide mediante la Matriz de confusión, que contiene información sobre la clase real y la prevista.\n",
    "\n",
    "| Realidad       | Precicción              | Description             |\n",
    "|----------------|-------------------------|-------------------------|\n",
    "|                | Clase positiva          | Clase Negativa          |\n",
    "| Clase positiva | Verdadero Positivo (TP) | Falso Negativo (FN)     |\n",
    "| Clase negativa | Falso Positivo (FP)     | Verdadero Negativo (TN) |\n",
    "\n",
    "$$ Acuracy=\\frac{TP+TN}{TP+TN+FP+FN} $$\n",
    "\n",
    "Sin embargo, mientras se trabaja en un dominio desequilibrado, la precisión no es una medida adecuada para evaluar el rendimiento del modelo. Por ejemplo: un clasificador que alcanza una precisión del 98% con una tasa de eventos del 2% no es exacto si clasifica todas las instancias como la clase mayoritaria. Y elimina el 2% de observaciones de clases minoritarias como ruido.\n",
    "\n",
    "## ¿Como manejamos datos desbalanceados?\n",
    "### A nivel de datos: técnicas de remuestreo\n",
    "Tratar con conjuntos de datos desequilibrados implica estrategias como mejorar los algoritmos de clasificación o equilibrar las clases en los datos de entrenamiento (preprocesamiento de datos) antes de proporcionar los datos como entrada al algoritmo de aprendizaje automático. Se prefiere la última técnica ya que tiene una aplicación más amplia.\n",
    "\n",
    "El objetivo principal de equilibrar las clases es aumentar la frecuencia de la clase minoritaria o disminuir la frecuencia de la clase mayoritaria. Esto se hace para obtener aproximadamente el mismo número de instancias para ambas clases. Veamos algunas técnicas de remuestreo:\n",
    "\n",
    "Antes de esto, presetaremos los datos que usaremos, estas la base de datos de kaggle [*Porto Seguro’s Safe Driver Prediction*](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data?select=train.csv), que es una base de datos en la que buscamos predecir si alguien usará o no su segturo de auto. Más datos en el link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131518</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224804</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875922</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444536</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "id                                                                    \n",
       "131518        0          2              4          9              0   \n",
       "1224804       0          1              1          2              0   \n",
       "875922        1          5              1          6              0   \n",
       "210458        0          0              1          6              1   \n",
       "444536        0          2              1          1              0   \n",
       "\n",
       "         ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "id                                                                    \n",
       "131518               0              0              1              0   \n",
       "1224804              0              0              1              0   \n",
       "875922               2              0              0              0   \n",
       "210458               6              0              1              0   \n",
       "444536               0              1              0              0   \n",
       "\n",
       "         ps_ind_09_bin  ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "id                      ...                                                   \n",
       "131518               0  ...           4           3           1           6   \n",
       "1224804              0  ...           6           1           5          10   \n",
       "875922               1  ...           6           2           1           4   \n",
       "210458               0  ...           4           5           4           3   \n",
       "444536               0  ...           4           0           1           9   \n",
       "\n",
       "         ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "id                                                                        \n",
       "131518                0               1               1               1   \n",
       "1224804               0               1               0               1   \n",
       "875922                0               0               1               0   \n",
       "210458                1               0               1               0   \n",
       "444536                0               1               1               0   \n",
       "\n",
       "         ps_calc_19_bin  ps_calc_20_bin  \n",
       "id                                       \n",
       "131518                0               0  \n",
       "1224804               1               0  \n",
       "875922                1               0  \n",
       "210458                0               0  \n",
       "444536                0               1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./input/train.csv', index_col = 'id').sample(10000)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ','_').str.replace('-','_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    9633\n",
       "1     367\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target').apply(lambda x : x.target.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos alredeos de un 3% de datos en los que se hace uso del seguro. Y ahora veremos 3 de tecnicas con en fin de tratar de balancear los datos. Pero antes vamos a separar los datos con tal de dejar algunos para realizar una prueba despues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700,\n",
       " 0    6444\n",
       " 1     256\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X = df[df.columns[1:]]\n",
    "y = df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "y_train.count(), y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro detalle, durante esta ayudantía usaremos los modulos `imblearn`, cuya documentación pueden encontrar [aquí](https://imbalanced-learn.readthedocs.io/), les ruego instalarlos en sus ambientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submuestreo aleatorio\n",
    "El submuestreo aleatorio tiene como objetivo equilibrar la distribución de clases eliminando aleatoriamente los ejemplos de clases mayoritarias. Esto se hace hasta que se equilibren las instancias de las clases mayoritaria y minoritaria.\n",
    "\n",
    "* Observaciones totales = 6700\n",
    "\n",
    "* Observaciones fraudulentas = 6441\n",
    "\n",
    "* Observaciones no fraudulentas = 259\n",
    "\n",
    "* Tasa de eventos = 3.5%\n",
    "\n",
    "En este caso, estamos tomando muestras del 10% sin reemplazo de instancias sin fraude. Y combinándolos con casos de fraude.\n",
    "\n",
    "* Observaciones no fraudulentas después de un muestreo aleatorio = 259\n",
    "\n",
    "* Observaciones totales después de combinarlas con observaciones fraudulentas = 259\n",
    "\n",
    "* Tasa de eventos para el nuevo conjunto de datos después de un muestreo insuficiente = 25%\n",
    "\n",
    " \n",
    "\n",
    "**Ventajas**\n",
    "* Puede ayudar a mejorar el tiempo de ejecución y los problemas de almacenamiento al reducir la cantidad de muestras de datos de entrenamiento cuando el conjunto de datos de entrenamiento es enorme.\n",
    "**Desventajas**\n",
    "* Puede descartar información potencialmente útil que podría ser importante para crear clasificadores de reglas.\n",
    "* La muestra elegida al azar bajo muestreo puede ser una muestra sesgada. Y no será un representante preciso de la población. Por lo tanto, resulta en resultados inexactos con el conjunto de datos de prueba real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    256\n",
       "0    256\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42,  sampling_strategy = 1)\n",
    "X_resampled_rus, y_resampled_rus = rus.fit_resample(X_train, y_train)\n",
    "y_resampled_rus.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que usamos `sampling_strategy = 1` como el ratio de los datos que usaremos, i.e. $\\frac{datos_{minoritrios}}{datos_{mayoritarios}}$, i.e., la misma cantidad de datos de los dos tipos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobremuestreo aleatorio\n",
    "El sobremuestreo aumenta el número de instancias en la clase minoritaria al replicarlas al azar para presentar una mayor representación de la clase minoritaria en la muestra.\n",
    "\n",
    "* Observaciones totales = 6700\n",
    "\n",
    "* Observaciones fraudulentas = 6441\n",
    "\n",
    "* Observaciones no fraudulentas = 259\n",
    "\n",
    "* Tasa de eventos = 3.5%\n",
    "\n",
    "En este caso, estamos replicando 20 observaciones de fraude 20 veces.\n",
    "\n",
    "* Observaciones no fraudulentas = 64548\n",
    "\n",
    "* Observaciones fraudulentas después de replicar las observaciones de la clase minoritaria = 6441\n",
    "\n",
    "* Observaciones totales en el nuevo conjunto de datos después del sobremuestreo = 6441\n",
    "\n",
    "* Tasa de eventos para el nuevo conjunto de datos después de un muestreo insuficiente = 50%\n",
    "\n",
    "**Ventajas**\n",
    "* A diferencia del muestreo, este método no produce pérdida de información.\n",
    "* Supera en rendimiento al submuestreo\n",
    "**Desventajas**\n",
    "* Aumenta la probabilidad de sobreajuste ya que replica los eventos de las clases minoritarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6444\n",
       "0    6444\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0, sampling_strategy = 1)\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train, y_train)\n",
    "y_resampled_ros.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Sobremuestreo informado: técnica sintética de sobremuestreo de minorías para datos desequilibrados (SMOTE) \n",
    "Se sigue esta técnica para evitar el sobreajuste que ocurre cuando se agregan réplicas exactas de instancias minoritarias al conjunto de datos principal. Se toma un subconjunto de datos de la clase minoritaria como ejemplo y luego se crean nuevas instancias sintéticas similares. Estas instancias sintéticas luego se agregan al conjunto de datos original. El nuevo conjunto de datos se utiliza como muestra para entrenar los modelos de clasificación.\n",
    "\n",
    "\n",
    "* Observaciones totales = 6700\n",
    "\n",
    "* Observaciones fraudulentas = 6441\n",
    "\n",
    "* Observaciones no fraudulentas = 259\n",
    "\n",
    "* Tasa de eventos = 3.5%\n",
    "\n",
    "Se toma una muestra de 15 instancias de la clase minoritaria y se generan 20 veces instancias sintéticas similares\n",
    "\n",
    "Después de la generación de instancias sintéticas, se crea el siguiente conjunto de datos\n",
    "\n",
    "* Clase de minoría (observaciones fraudulentas) = 6441\n",
    "\n",
    "* Clase mayoritaria (observaciones no fraudulentas) = 6441\n",
    "\n",
    "* Tasa de eventos = 50%\n",
    "\n",
    " \n",
    "\n",
    "**Ventajas**\n",
    "* Mitiga el problema del sobreajuste causado por el sobremuestreo aleatorio, ya que se generan ejemplos sintéticos en lugar de la replicación de instancias.\n",
    "* Sin pérdida de información útil\n",
    "Desventajas\n",
    "* Al generar ejemplos sintéticos, SMOTE no tiene en cuenta los ejemplos vecinos de otras clases. Esto puede resultar en un aumento en la superposición de clases y puede introducir ruido adicional\n",
    "* SMOTE no es muy eficaz para datos de gran dimensión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6444\n",
       "0    6444\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled_smote, y_resampled_smote = SMOTE(random_state = 42,sampling_strategy = 1).fit_resample(X_train, y_train)\n",
    "y_resampled_smote.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hagamos un test rápdio para ver como se comportan estos tres métodosk, para esto usaremos una *SVM* con cada uno de los :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_ros = svm.SVC()\n",
    "clf_rus = svm.SVC()\n",
    "clf_smote = svm.SVC()\n",
    "clf_ros.fit(X_resampled_ros, y_resampled_ros)\n",
    "clf_rus.fit(X_resampled_rus, y_resampled_rus)\n",
    "clf_smote.fit(X_resampled_smote, y_resampled_smote)\n",
    "preds_ros = clf_ros.predict(X_test)\n",
    "preds_rus = clf_rus.predict(X_test)\n",
    "preds_smote = clf_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presicion Randon Over Sampling: 0.623030303030303\n",
      "Presicion Random Under Sampling: 0.6827272727272727\n",
      "Presicion SMOTE: 0.8009090909090909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_ros = accuracy_score(y_test, preds_ros)\n",
    "acc_rus = accuracy_score(y_test, preds_rus)\n",
    "acc_smote = accuracy_score(y_test, preds_smote)\n",
    "\n",
    "print(f'Presicion Randon Over Sampling: {acc_ros}')\n",
    "print(f'Presicion Random Under Sampling: {acc_rus}')\n",
    "print(f'Presicion SMOTE: {acc_smote}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestros resultados del Over Sampling y el under Sampling son similares, pero SMOTE claramente muestra una mejora sobre los otros dos, \n",
    "\n",
    "Estás no son la únicas formas que existen de realizar este preoceso, de particular interes es *MSMOTE*, un algortimo que se basa en *SMOTE*, y *ADASYN*, un metodo totalmente diferente, ambos están bien explicados en la [documentacion](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#smote-variants) de *imblearn*, Pero además de estás existen muchas técnicas distintas que nos pueden ayudar a manejarnos con estos datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad\n",
    "\n",
    "Ahora usaremos otro *dataset* de kaggle, en este caso [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud), en estos datos buscamos detectar que transacciones son fraudulentas, y cuales son reales. Para esto, tenemos 28 variables \"incognitas\" (solo sabemos que son el resultado de un algoritmo de reducción de dimensión), el monto de la transacción y si está es o no fraudulenta, veamos como es el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145439</th>\n",
       "      <td>86945.0</td>\n",
       "      <td>-0.343694</td>\n",
       "      <td>0.720691</td>\n",
       "      <td>3.746195</td>\n",
       "      <td>5.094463</td>\n",
       "      <td>-1.545430</td>\n",
       "      <td>1.666376</td>\n",
       "      <td>-0.346986</td>\n",
       "      <td>0.264082</td>\n",
       "      <td>-0.064563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176104</td>\n",
       "      <td>1.149892</td>\n",
       "      <td>-0.085483</td>\n",
       "      <td>0.968228</td>\n",
       "      <td>-0.690584</td>\n",
       "      <td>0.447159</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>-0.055585</td>\n",
       "      <td>82.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69521</th>\n",
       "      <td>53461.0</td>\n",
       "      <td>-1.245406</td>\n",
       "      <td>0.573329</td>\n",
       "      <td>1.944124</td>\n",
       "      <td>-0.074705</td>\n",
       "      <td>-0.038978</td>\n",
       "      <td>2.131605</td>\n",
       "      <td>-0.706079</td>\n",
       "      <td>1.273053</td>\n",
       "      <td>-0.112872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232128</td>\n",
       "      <td>0.763191</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>-0.980210</td>\n",
       "      <td>-0.612544</td>\n",
       "      <td>0.369466</td>\n",
       "      <td>-0.062142</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>16.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94935</th>\n",
       "      <td>65096.0</td>\n",
       "      <td>-0.351543</td>\n",
       "      <td>-0.300946</td>\n",
       "      <td>2.641319</td>\n",
       "      <td>-0.806061</td>\n",
       "      <td>-0.957076</td>\n",
       "      <td>0.691816</td>\n",
       "      <td>-0.465904</td>\n",
       "      <td>0.214132</td>\n",
       "      <td>-0.827099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361567</td>\n",
       "      <td>-0.282835</td>\n",
       "      <td>-0.024364</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>-0.607030</td>\n",
       "      <td>1.024715</td>\n",
       "      <td>-0.068631</td>\n",
       "      <td>-0.125628</td>\n",
       "      <td>22.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139733</th>\n",
       "      <td>83321.0</td>\n",
       "      <td>1.199730</td>\n",
       "      <td>-0.599636</td>\n",
       "      <td>1.018696</td>\n",
       "      <td>0.634702</td>\n",
       "      <td>-1.186224</td>\n",
       "      <td>0.074857</td>\n",
       "      <td>-0.829334</td>\n",
       "      <td>0.037398</td>\n",
       "      <td>-0.422757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379055</td>\n",
       "      <td>-0.581001</td>\n",
       "      <td>-0.029995</td>\n",
       "      <td>-0.150791</td>\n",
       "      <td>0.333131</td>\n",
       "      <td>-0.372862</td>\n",
       "      <td>0.084359</td>\n",
       "      <td>0.049202</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>49080.0</td>\n",
       "      <td>-2.042650</td>\n",
       "      <td>0.767907</td>\n",
       "      <td>1.304693</td>\n",
       "      <td>1.140445</td>\n",
       "      <td>-2.345648</td>\n",
       "      <td>1.200739</td>\n",
       "      <td>-0.603841</td>\n",
       "      <td>1.197886</td>\n",
       "      <td>1.368857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136099</td>\n",
       "      <td>0.145786</td>\n",
       "      <td>0.100748</td>\n",
       "      <td>0.117094</td>\n",
       "      <td>-0.410084</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.079144</td>\n",
       "      <td>-0.010333</td>\n",
       "      <td>149.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time        v1        v2        v3        v4        v5        v6  \\\n",
       "145439  86945.0 -0.343694  0.720691  3.746195  5.094463 -1.545430  1.666376   \n",
       "69521   53461.0 -1.245406  0.573329  1.944124 -0.074705 -0.038978  2.131605   \n",
       "94935   65096.0 -0.351543 -0.300946  2.641319 -0.806061 -0.957076  0.691816   \n",
       "139733  83321.0  1.199730 -0.599636  1.018696  0.634702 -1.186224  0.074857   \n",
       "59943   49080.0 -2.042650  0.767907  1.304693  1.140445 -2.345648  1.200739   \n",
       "\n",
       "              v7        v8        v9  ...       v21       v22       v23  \\\n",
       "145439 -0.346986  0.264082 -0.064563  ...  0.176104  1.149892 -0.085483   \n",
       "69521  -0.706079  1.273053 -0.112872  ...  0.232128  0.763191  0.008072   \n",
       "94935  -0.465904  0.214132 -0.827099  ... -0.361567 -0.282835 -0.024364   \n",
       "139733 -0.829334  0.037398 -0.422757  ... -0.379055 -0.581001 -0.029995   \n",
       "59943  -0.603841  1.197886  1.368857  ... -0.136099  0.145786  0.100748   \n",
       "\n",
       "             v24       v25       v26       v27       v28  amount  class  \n",
       "145439  0.968228 -0.690584  0.447159  0.014067 -0.055585   82.74      0  \n",
       "69521  -0.980210 -0.612544  0.369466 -0.062142  0.017276   16.90      0  \n",
       "94935   0.035166 -0.607030  1.024715 -0.068631 -0.125628   22.44      0  \n",
       "139733 -0.150791  0.333131 -0.372862  0.084359  0.049202   64.00      0  \n",
       "59943   0.117094 -0.410084  0.494700  0.079144 -0.010333  149.95      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_cards = pd.read_csv('./input/creditcard.csv').sample(10000) #si le tienen fe a su PC pueden aumentar este numero\n",
    "credit_cards.columns = credit_cards.columns.str.strip().str.lower().str.replace(' ','_').str.replace('-','_')\n",
    "credit_cards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como el la distribución dentre las transacciónes fraudulentas y las que no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    9974\n",
       "1      26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_cards.groupby('class').apply(lambda x : x['class'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay una mucha menos cantidad de transacciones fraudulentas que las que no lo son. Ahora, utiliza `SMOTE` y otro modelo que estimes convieniente (puede ser ROS, RUS, u otro de la documentación de *imblearn* que te llame la atención, recomiendo prestar atención a `ADASYN`, otro modelo ampliamente usado para esta finalidad), y luego compara su despeño en dos modelos, una SVM y otro de tu elección, el rendimiento de estos modelos. Tambien puedes jugar con el parámetro `sampling_strategy = x` y ver cual te genera menores resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
